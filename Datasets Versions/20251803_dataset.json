[
    {
        "title": "Generative Adversarial Networks for Multi-Instrument Music Synthesis",
        "university": "University of Passau",
        "year": "2020",
        "abstract": "Generative Adversarial Networks (GANs) recently succeeded in various tasks of humans creative domain. In this masters thesis, based on a GAN a score-to-audio model is designed, built and analyzed. The model termed orGAN interprets sheet music by controlling on- and offsets, volume, instrumental interaction etc., taking the role of a human performer. It is capable of synthesizing scores of arbitrary length for arbitrary combinations of 13 types of instruments at once with a very high-quality sampling rate of 48kHz. For this, scores represented as pianorolls are transformed into a spectrogram. This way, generative model architectures from computer vision become applicable. After investigating the methodological concepts in depth, this masters thesis adapts a well-known image-to-image translation neural network architecture: orGAN is a conditional PatchGAN with fully-convolutional U-Net generator and an auxiliary instrument classifier. Experiments confirm the findings of pix2pix [27] regarding the patch size and show the superiority of the Multi-Scale Structural Similarity Index (MS-SSIM) over the L1 loss in a composite objective function. The instrument classifier is found to foster transfer learning from single- to multi-instrument play. Extensive human evaluation shows a superiority of orGAN over related work and state-of-the art synthesizers in naturalness, timbre and emotional expressiveness of the generated audio.",
        "contents": "GAN architecture, training datasets, evaluation metrics, application to music generation.",
        "problem_description": "Music synthesis has traditionally relied on rule-based systems and digital signal processing techniques. However, these approaches struggle to generate complex multi-instrument compositions that sound natural. With recent advancements in machine learning, particularly Generative Adversarial Networks (GANs), there is an opportunity to create more expressive and high-quality synthesized music that can closely resemble human performances.",
        "problem_motivation": "This thesis focuses on using GANs to synthesize multi-instrumental music by transforming sheet music representations into realistic audio outputs. The proposed model, orGAN, employs a PatchGAN-based architecture combined with a U-Net generator and an auxiliary instrument classifier to improve sound quality. The study evaluates the model using human perception tests, confirming that it outperforms conventional synthesis techniques in expressiveness, timbre, and naturalness."
      },
      {
        "title": "Machine Learning Image Segmentation to Improve Object Recognition in Mixed Reality",
        "university": "Technical University of Munich (TUM)",
        "year": "2020",
        "abstract": "Object recognition represents an emerging technology in the field of image processing able to detect and label objects through the recognition of patterns in images. At the same time, Mixed Reality represents the combination of the virtual and physical worlds in a bid to yield a digital environment where elements from both dimensions co-exist. Through the integration of an image segmentation algorithm along with image enhancement techniques, this thesis aims to facilitate the navigation experience in Mixed Reality by recognizing more efficiently those objects that provide relevant information to users to navigate. The image segmentation algorithm and the image enhancement techniques are implemented in a video recording, in such a way that through the detection and modification of object features, their instances are either visually highlighted or downgraded according to the information they provide to fulfill the navigation task. Subsequently, in order to determine the impact on human perception, two user tests are conducted. In the first test, users are asked to focus their attention on a virtual element and select the objects that attract their attention the most. In the second test, in which the methodology of this thesis is implemented, users are also asked to focus on a virtual element added to the video and choose the elements that are most striking to them. The results show that the technique used to highlight objects allowed users to recognize them more easily. In contrast, the objects that were downgraded remained eye-catching to users.",
        "contents": "Image segmentation, mixed reality applications, convolutional neural networks (CNNs), dataset augmentation.",
        "problem_description": "Mixed Reality (MR) applications require robust object recognition to blend digital and real-world elements seamlessly. However, traditional object detection methods struggle with complex and dynamic environments, leading to inaccurate or delayed recognition. Improved image segmentation techniques can enhance object detection and user interactions in MR settings.",
        "problem_motivation": "This research integrates image segmentation algorithms with image enhancement techniques to improve object recognition in MR environments. The study conducts user experiments to evaluate the effectiveness of these enhancements in guiding attention and navigation. Results indicate that the proposed approach significantly improves object visibility and recognition efficiency in MR applications."
      },
      {
        "title": "Self-supervised Domain Adaptation of Language Models for the Process Industry",
        "year": "2024",
        "abstract": "Incorporating additional knowledge into pre-trained language models (PLMs) has proven to be highly effective in improving their performance in specialized fields. Graph structures, in particular, allow models to capture domain-specific relationships between documents that would otherwise be missed. In the process industry, where unstructured text logs document critical operational insights, leveraging these relationships becomes essential for improving document representation. This thesis proposes a graph-aware domain adaptation method aimed at enhancing the representations of PLMs for the process industry. Building upon SciNCL, a neighborhood contrastive learning approach, the study constructs a process industry graph comprising functional locations and maintenance text logs to sample document pairs for contrastive learning. The proposed method outperformed baseline models in a semantic search task, with the best-performing model achieving an nDCG@10 score 9 points higher than the best baseline. These findings encourage further exploration of graph-based domain adaptation techniques, particularly in domains characterized by sparse document connections and limited data availability.",
        "contents": "Self-supervised learning, language models, domain adaptation, process industry applications.",
        "problem_description": "This thesis presents a graph-aware self-supervised learning approach to adapt language models to the process industry. By constructing a process industry graph and leveraging contrastive learning, the model enhances document representation. The study demonstrates that the proposed method improves semantic search performance and encourages further research into graph-based domain adaptation techniques.",
        "problem_motivation": "Pre-trained language models perform well in general domains but struggle with specialized industrial contexts due to the lack of labeled data. The process industry relies heavily on unstructured text logs, and improving language model adaptation can enhance information retrieval, fault detection, and predictive maintenance."
      },
      {
        "title": "Deep Learning Techniques Applied to Constituency Parsing of German",
        "university": "University of Koblenz Landau",
        "year": "2020",
        "abstract": "",
        "problem_description": "This study develops a neural network-based constituency parser for German. The approach leverages self-attention mechanisms and multi-layered architectures to improve syntactic structure extraction. The model achieves state-of-the-art accuracy on benchmark datasets, demonstrating the effectiveness of deep learning for German constituency parsing.",
        "problem_motivation": "Natural language processing applications such as grammar checking and machine translation require accurate syntactic parsing. Traditional parsing methods for German have limitations due to the language's complex word order and inflectional morphology. Deep learning techniques offer a promising solution to improve parsing accuracy."
      },
      {
        "title": "Applying Deep Reinforcement Learning in the Navigation of Mobile Robots in Static and Dynamic Environments",
        "year": "2019",
        "abstract": "Nowadays mobile robots operate reliably in clean static environments like industry setups, but rather fail in complex dynamic environments, like e.g. airports or shopping centers. Those environments are more crowded and narrow than industry-like environments and contain moving objects — mainly humans. Traditional navigation approaches treat all objects as static objects, resulting in a non-reasonable behavior. Mobile robots should be able to cope with dynamic objects as well as dynamic crowds. In this thesis, local planning is realized with the state-of-the-art Deep Reinforcement Learning (DRL) approach Proximal Policy Optimization (PPO). The RL-agent is trained in a 2D-simulation environment, where it collects experiences to update the Deep Neural Network, that serves as a function approximator. First, several RL-agents are trained in a static industry-like task setup and compared to traditional navigation approaches. Second, profiting from the knowledge of the static training, agents were trained in adynamic environment with simulated humans, behaving according to Helbing’s Social Force Model. Two different behaviors worth mentioning have been evolved. One agent learned a policy, that avoids individual humans, but stops and waits if the robot faces unsolvable situations like crowds or blocked passages. The other agent learned a more aggressive policy. It can push pedestrians by driving very slowly towards them until they give way.",
        "contents": "Reinforcement learning, mobile robotics, navigation, deep Q-networks, policy optimization.",
        "university": "Universität Hamburg",
        "problem_description": "This thesis employs Proximal Policy Optimization (PPO) to train reinforcement learning agents for robot navigation. The agents are trained in simulated environments, learning policies to handle human crowds and obstacles. The study compares different training strategies and evaluates their effectiveness in improving autonomous navigation.",
        "problem_motivation": "Autonomous mobile robots must navigate environments that contain both static and dynamic obstacles. Traditional navigation approaches assume static obstacles, leading to inefficient or unsafe behavior in dynamic settings such as airports and shopping centers. Reinforcement learning can help robots adapt to dynamic environments."

      },
      {
        "title": "Graph Neural Networks for Electrical Grid State Estimation",
        "year": "2024",
        "abstract": "Increasing loads on the Low-voltage network (LVN) require constant status checks.The health status of a LVN can be determined using an automated Electrical grid power system state estimation (SE). The reformulation of the State estimation task (SE-task) uses heterogeneous graph concepts. Using Graph Neural Networks (GNNs), applied complex voltage can be gained in spare measured girds. A date-fitting concept is presented, for parsing LVN into a proper data structure. The author presents the GNN GSETR, capable of performing the SE. A great performance of 99 % is reached by GSETR, knowing all power measurements. Moreover, this work demonstrates the robustness of the model. For this purpose, the measured power data is only sparsely available to the model. A 91 % accuracy is achieved, in this second scenario.",
        "contents": "Graph neural networks, electrical grid optimization, power system state estimation.",
        "problem_description": "This research introduces GSETR, a GNN-based model for electrical grid state estimation. The model uses graph structures to infer voltage states in low-voltage networks with sparse measurements. Experimental results demonstrate that the proposed method achieves high accuracy, even with limited sensor data.",
        "problem_motivation": "Modern electrical grids require real-time state estimation to maintain stability and efficiency. Traditional estimation methods struggle with incomplete data and computational constraints. Graph Neural Networks (GNNs) offer a promising approach to enhance state estimation accuracy in power systems."
      },
      {
        "title": "Representation Learning on Electronic Health Records Using Graph Neural Networks",
        "year": "2023",
        "abstract": "The digitization of healthcare has led to a proliferation of electronic health records, providing valuable data for machine learning algorithms(e.g., graph neural networks) to make accurate predictions about patients outcomes(e.g., mortality prediction). This thesis investigates different aspects of representation learning on electronic health records using a graph neural network and provides new insights into the area of graph modelling, feature ablation, and helps to understand the effect of bias in the graph structure. It also evaluates the models underlying predictors with well-established statistical models (SAPS-II & SAPS-III) for predicting the mortality of the patients diagnosed with sepsis using the MIMIC-III dataset. The experimentation shows that the lab and vital signs features used in predicting mortality in SAPS-II and SAPS-III are ranked in the top 90 percentile amongst the predictors of mortality in the used heterogeneous Graph Attention Network (GAT) model. Experimentation with different graph representations(different ways of representing data in nodes and edges in a heterogeneous graph) shows their advantages and disadvantages. However, in terms of area under receiver operating characteristics curve (Area under the receiver operating curves (AUROC)), different representations performed similarly well. The general way of modelling time-dependent measurements with multiple edges without any aggregation or transformation of edge data had no bias but performed worse in GPU utilization and memory usage. Different ways of encoding the categorical and text data also had an impact on the models performance, wherein the encoding of such data with a clinical text pre-trained UMLSBert model had better performance than the label or one-hot encoding. Furthermore, the GAT model is tested by introducing an additionally highly biased relationship (similar demography). It was seen that the models attention mechanism corrected such a nature of bias. Finally, the experiments showed that drugs were the best predictors of mortality among labs, vitals, or diagnoses.",
        "contents": "Graph neural networks, healthcare analytics, representation learning, patient record analysis.",
        "problem_description": "This thesis explores the application of GNNs to EHR data for mortality prediction. The study evaluates different graph representations and encoding techniques, demonstrating that GNN-based models outperform traditional methods in predicting patient outcomes. The findings highlight the potential of GNNs in medical analytics.",
        "problem_motivation": "Electronic health records (EHRs) contain valuable patient data that can improve medical decision-making. However, existing predictive models struggle with complex relationships in patient data, leading to suboptimal performance. Graph Neural Networks (GNNs) can enhance representation learning and improve patient outcome predictions."
      },
      {
        "title": "Deep Reinforcement Learning for Decentralized Autonomous Decision-Making in Federated Satellite Systems",
        "year": "2024",
        "abstract": "Constituent parsing attempts to extract syntactic structure from a sentence. These parsing systems are helpful in many NLP applications such as grammar checking, question answering, and information extraction. This thesis work is about implementing a constituent parser for German language using neural networks. Over the past, recurrent neural networks have been used in building a parser and also many NLP applications. In this, self-attention neural network modules are used intensively to understand sentences effectively. With multi-layered self-attention networks, constituent parsing achieves 93.68% F1 score. This is improved even further by using both character and word embeddings as a representation of the input. An F1 score of 94.10% was the best achieved by constituent parser using only the dataset provided. With the help of external datasets such as German Wikipedia, pre-trained ELMo models are used along with self-attention networks achieving 95.87% F1 score.",
        "contents": "Federated learning, reinforcement learning, autonomous satellites, decentralized control.",
        "problem_description": "This study applies deep reinforcement learning (DRL) to federated satellite networks, training agents to optimize observation, data sharing, and energy management tasks. The research compares different DRL algorithms and evaluates their effectiveness in decentralized satellite coordination. The results indicate that DRL-based approaches can significantly improve mission efficiency.",
        "problem_motivation": "The growing number of satellites in orbit necessitates autonomous decision-making for efficient resource management. Centralized control is infeasible for large satellite constellations due to communication delays and scalability issues. Decentralized learning approaches can enable autonomous coordination among satellites."
      },
      {
        "Title": "Solving Machine Learning Problems",
        "Problem Description": "This thesis presents a machine learning model capable of solving university-level machine learning problems using a dataset generated from MITs 6.036 Introduction to Machine Learning course. The model is trained on a dataset consisting of course exercises, homework, and quiz questions, spanning 12 major machine learning topics. The system employs Transformer models within an encoder-decoder architecture enhanced with graph neural networks (GNNs) and expression trees to generate structured responses. By successfully training a machine learning model to answer machine learning questions at an expert level, this work establishes a foundation for AI-driven education in technical disciplines. The system demonstrates real-time problem-solving capabilities and opens new avenues for automated tutoring and assessment systems in machine learning education.",
        "Problem Motivation": "Machine learning models have demonstrated remarkable success in various tasks, but their application to solving structured machine learning problems remains largely unexplored. While natural language processing models like GPT-3 can handle text-based reasoning, they struggle with STEM subjects that require formal logic and mathematical problem-solving. Current state-of-the-art models fail at solving university-level coursework, particularly in technical disciplines like machine learning. The challenge lies in teaching machines to understand and reason through structured problems in an educational setting. By developing an automated system that can learn machine learning concepts and solve related coursework, we can advance AI’s role in STEM education and create intelligent tutoring systems that assist students in their learning journey.",
        "Year": "2021",
        "Abstract": "Can a machine learn Machine Learning? This work trains a machine learning model to solve machine learning problems from a University undergraduate level course. We generate a new training set of questions and answers consisting of course exercises, homework, and quiz questions from MIT’s 6.036 Introduction to Machine Learning course and train a machine learning model to answer these questions. Our system demonstrates an overall accuracy of 96% for open-response questions and 97% for multiple-choice questions, compared with MIT students’ average of 93%, achieving grade A performance in the course, all in real-time. Questions cover all 12 topics taught in the course, excluding coding questions or questions with images. Topics include: (i) basic machine learning principles; (ii) perceptrons; (iii) feature extraction and selection; (iv) logistic regression; (v) regression; (vi) neural networks; (vii) advanced neural networks; (viii) convolutional neural networks; (ix) recurrent neural networks; (x) state machines and MDPs; (xi) reinforcement learning; and (xii) decision trees. Our system uses Transformer models within an encoder-decoder architecture with graph and tree representations. An important aspect of our approach is a data-augmentation scheme for generating new example problems. We also train a machine learning model to generate problem hints. Thus, our system automatically generates new questions across topics, answers both open-response questions and multiple-choice questions, classifies problems, and generates problem hints, pushing the envelope of AI for STEM education."
    },
    {
        "title": "Optimization Methods for Machine Learning underStructural Constraints",
        "Problem Description":"This thesis develops scalable optimization methods for constrained machine learning problems by addressing various structural constraints. First, it proposes novel algorithms for subgradient regularized convex regression, ensuring linear convergence and efficiently solving large-scale instances with high-dimensional data. Next, it introduces a computational framework for log-concave density MLE, leveraging smoothing techniques and integral discretization to achieve significant runtime improvements over existing convex approaches. Additionally, the thesis presents an ℓ₀ℓ₂-penalized pseudolikelihood estimator for Gaussian Graphical Models, demonstrating superior computational efficiency and statistical performance compared to traditional ℓ₁-based methods. Finally, it enhances Branch-and-Bound (BnB) solvers for sparse learning by incorporating a screening procedure that reduces computational overhead, enabling faster optimization in high-dimensional problems. These advancements contribute to more efficient and scalable solutions for complex machine learning models.",
        "Problem Motivation":"Modern statistical and machine learning models impose structural constraints for interpretability and complexity reduction. Efficient optimization methods are needed to handle large-scale problems with constraints like shape restrictions in nonparametric statistics and sparsity in high-dimensional statistics.",
        "Year": "2022",
        "Abstract": "In this thesis, we present scalable optimization methods for large-scale machine learning problems under structural constraints, focusing on shape constraints in nonparametric statistics and sparsity in high-dimensional statistics.We first address the subgradient regularized convex regression problem, proposing novel large-scale algorithms based on proximal gradient descent and active set methods, with linear convergence guarantees. Our framework efficiently solves instances with n=105 n=105, d=10 d=10 within minutes. Next, we develop a new computational framework for log-concave density MLE, utilizing smoothing techniques and integral discretization to improve runtime over earlier convex approaches. For Gaussian Graphical Models, we propose an ℓ₀ℓ₂-penalized pseudolikelihood estimator, solving a mixed integer programming (MIP) formulation via a specialized nonlinear Branch-and-Bound (BnB) framework. Our method scales to v<=10,000 p<=10,000 and outperforms ℓ₁-based approaches in both speed and statistical performance.Finally, we enhance the BnB framework for sparse learning with a novel screening procedure that fixes relaxed variables to 0 or 1, significantly reducing solver runtimes."
    },
    {
        "title":"Probabilistic data analysis with probabilistic programming",
        "Problem Description":"This thesis defines Composable Generative Population Models (CGPMs) as a structured way to describe probabilistic models and integrate them into BayesDB for performing probabilistic data analysis. CGPMs specify a table of observable random variables, enabling complex intra-row dependencies as well as inter-row relationships mediated through latent variables. The framework supports multiple probabilistic modeling techniques, including hierarchical Bayesian models, kernel density estimation, discriminative machine learning, clustering algorithms, and dimensionality reduction methods.",
        "Problem Motivation":"Probabilistic techniques play a crucial role in data analysis but are often difficult to apply, combine, and compare across different modeling approaches. Traditional methods such as parametric statistical modeling, machine learning, and probabilistic programming each have their own formalisms and assumptions, making it challenging to create a unified framework for probabilistic data analysis. To address these challenges, this thesis introduces Composable Generative Population Models (CGPMs)—a novel computational abstraction that extends graphical models for use in probabilistic programming. By integrating CGPMs into BayesDB, a probabilistic programming platform, this research aims to provide a more flexible and scalable approach to probabilistic data analysis across a variety of tasks.",
        "Year": "2016",
        "Abstract": "Probabilistic techniques are central to data analysis, but dierent approaches can be challenging to apply, combine, and compare. This thesis introduces composable generative population models (CGPMs), a computational abstraction that extends directed graphical models and can be used to describe and compose a broad class of probabilistic data analysis techniques. Examples include hierarchical Bayesian models, multivariate kernel methods, discriminative machine learning, clustering algorithms, dimensionality reduction, and arbitrary probabilistic programs. We also demonstrate the integration of CGPMs into BayesDB, a probabilistic programming platform that can express data analysis tasks using a modeling language and a structured query language. The practical value is illustrated in two ways. First, CGPMs are used in an analysis that identifies satellite data records which probably violate Kepler's Third Law, by composing causal probabilistic programs with non-parametric Bayes in under 50 lines of probabilistic code. Second, for several representative data analysis tasks, we report on lines of code and accuracy measurements of various CGPMs, plus comparisons with standard baseline solutions from Python and MATLAB libraries."
    },
    {
        "title":"Artificial intelligence-assisted data analysis with BayesDB",
        "Problem Description":"This thesis addresses challenges in real-world data analysis, particularly missing data and predictive model errors, using BayesDB, a probabilistic programming platform. Traditional imputation methods often fail to capture dependencies in data, leading to biased or inaccurate results. This work leverages BayesDB CrossCat model to improve missing data imputation and analyze predictive errors. First, it explores detecting systematic missing data patterns, distinguishing between MCAR, MAR, and MNAR scenarios to guide imputation strategies. Next, it evaluates CrossCat’s performance against standard imputation methods using the ANES dataset, demonstrating superior calibration and accuracy. Finally, it introduces a generative monitoring model to detect systematic errors in predictive models, analyzing bias using data from Gapminder and ANES. The findings highlight BayesDB's ability to enhance model interpretability and improve decision-making in data-driven applications.",
        "Problem Motivation":"When applying machine learning and statistical techniques to real-world datasets, several challenges arise, particularly due to missing data and errors from predictive models. Traditional data analysis methods struggle to handle incomplete datasets effectively, leading to biased or inaccurate conclusions. Additionally, black-box predictive models often produce results that are difficult to interpret, making it challenging to assess their reliability. To address these issues, this thesis explores the use of BayesDB, a probabilistic programming platform that enables efficient modeling, imputation of missing values, and characterization of predictive errors. By leveraging BayesDB's CrossCat model, this research aims to enhance data analysis workflows, improve imputation accuracy, and provide better insights into the behavior of predictive models.",
        "Year": "2017",
        "Abstract": "When applying machine learning and statistics techniques to real-world datasets, problems often arise due to missing data or errors from black-box predictive models that are difficult to understand or explain in terms of the model's inputs. This thesis explores the applicability of BayesDB, a probabilistic programming platform for data analysis, to three common problems in data analysis: (i) modeling patterns of missing data, (ii) imputing missing values in datasets, and (iii) characterizing the error behavior of predictive models. Experiments show that CrossCat, the default model discovery mechanism used by BayesDB, can address all three problems effectively. Examples are drawn from the American National Election Studies and the Gapminder database of global macroeconomic and public health indicators."
    },
    {
        "title":"Data analysis and simulation approach to capacity planning",
        "Problem Description":"This study focuses on capacity planning for military mental health services, specifically at an outpatient unit in a U.S. Army installation (Site Alpha). It examines system inefficiencies, including provider shortages, patient distribution, and high-utilizer cases, which contribute to long wait times and unmet care demands. Using causal loop diagrams and simulation modeling techniques, the research evaluates how different resource allocations impact system performance. The results suggest that before adding more resources, inefficiencies in the existing system must be addressed, particularly in the distribution of providers and workload balancing. This thesis highlights the need for data-driven decision-making in capacity planning to ensure sustainable and effective mental health service delivery within military settings.",
        "Problem Motivation":"The demand for mental health services within the U.S. military has increased significantly, particularly due to the long-term impact of deployments in recent conflicts. However, inefficiencies in the system prevent effective capacity planning, leading to bottlenecks, inadequate provider distribution, and delayed access to care. Traditional approaches to capacity expansion often fail due to systemic inefficiencies, making it necessary to adopt a holistic, systems-based approach to redesign mental health service capacity. This thesis seeks to improve the military mental health system by analyzing capacity constraints and proposing simulation-based models to optimize resource allocation.",
        "Year": "2015",
        "Abstract": "In 2012, President Obama signed an Executive Order to improve access to mental health service for active duty members and for veterans. Two years later, in 2014, the President outlined 19 new executive actions to improve the lives of service members with a focus on improving access to mental health care. These actions placed a priority on improving the capacity to provide mental health care. This thesis examines ways of improving the capacity of the mental health system with a focus on system redesign. I review capacity planning, provide a literature review of simulation methods and present a simulation, and data analysis of Site Alpha, a U.S. Army Installation. I also use causal loop diagrams to explore other feasible scenarios that affect care capacity. The key take-away from this work is that system inefficiencies should be dealt with before more resources can be effectively added and used in the system. Another pertinent finding is that the distribution of the providers in the system should be improved. The system also contains high utilizer patients who must be considered when planning for care. The mental health system is extremely complex and risks becoming even more complex. However, by adopting a holistic, systems approach to capacity planning the complexity can be managed."
    },
    {
        "title":"Faster linear algebra for data analysis and machine learning",
        "Problem Description":"This thesis develops new fast linear algebra algorithms for large-scale machine learning and data analysis. It introduces importance sampling techniques to accelerate matrix approximation, SVD, and ridge regression, improving computational efficiency while preserving accuracy. The study also presents fast iterative methods for kernel-based learning, enhancing kernel PCA, kernel ridge regression, and kernel k-means clustering. Additionally, it explores randomized sketching techniques that drastically reduce memory and computational costs without sacrificing performance. The proposed methods are validated through experiments demonstrating their practical effectiveness in large-scale data analysis tasks.",
        "Problem Motivation":"Linear algebra is fundamental to data analysis and machine learning, powering essential techniques like singular value decomposition (SVD), low-rank approximation, clustering, and kernel methods. However, as datasets grow, traditional matrix algorithms become computationally infeasible. This thesis addresses the need for faster, scalable, and memory-efficient linear algebra methods by leveraging random sampling, iterative refinement, and matrix sketching. These techniques aim to significantly reduce computation while maintaining provable accuracy, making large-scale machine learning applications more efficient.",
        "Year": "2018",
        "Abstract": "We study fast algorithms for linear algebraic problems that are ubiquitous in data analysis and machine learning. Examples include singular value decomposition and low-rank approximation, several varieties of linear regression, data clustering, and nonlinear kernel methods. To scale these problems to massive datasets, we design new algorithms based on random sampling and iterative refinement, tools that have become an essential part of modern computational linear algebra. We focus on methods that are provably accurate and efficient, while working well in practical applications. Open source code for many of the methods discussed in this thesis can be found at https://github.com/cpmusco."
    },
    {
        "title":"Emotional response modeling in financial markets : Boston Stock Exchange data analysis",
        "Problem Description":"This study examines physiological responses (such as heart rate variability, skin conductance, and tension) in professional traders to identify their reactions to market events. Data was collected from traders at the Boston Stock Exchange, tracking physiological markers alongside financial transactions. The study defines key event markers, including trade size, bid/ask spread width, long vs. short positions, and profit/loss performance, to analyze how different trading conditions affect physiological states. The results indicate that negative performance events (e.g., losses) trigger stronger physiological responses than positive ones, with prolonged negative performance leading to greater stress indicators. This research highlights the critical role of emotional and physiological factors in financial risk processing, suggesting that behavioral insights can enhance trading strategies and decision-making models.",
        "Problem Motivation":"Financial decision-making has traditionally been modeled using rational economic theories, assuming that market participants act logically based on all available information. However, behavioral finance suggests that emotional and physiological factors significantly influence risk perception and trading behavior. This thesis investigates the relationship between physiological responses and financial market decisions, aiming to understand how emotional reactions impact professional traders decision-making processes. By analyzing biometric data from market makers at the Boston Stock Exchange, the study seeks to uncover patterns of physiological changes associated with different trading events.",
        "Year": "2004",
        "Abstract": "In this thesis, physiological data is analyzed in the context of financial risk processing, specifically investigating the effects of financial trading decisions and situations on the physiological responses of professional market makers. The data for this analysis comes from an experiment performed on market makers at the Boston Stock Exchange. This analysis involved significant preprocessing of large financial and physiological data sets. Short-term and long term analysis of financial and performance based event markers of the data are performed and the results interpreted. There are two main conclusions. First, negative performance events are found to be the the main driver of physiological responses; positive performance events have minimal deviations from baseline physiological signals. Second, a long term analysis of events yield more substantial physiological changes than a short term analysis."
    },
    {
        "title": "Reverse Question Answering: Can an LLM Write a Question so Hard (or Bad) that it Can't Answer?",
        "Problem Description":"This study investigates Reverse Question Answering (RQA), where an LLM generates a question given an answer and then attempts to answer it. It analyzes how well LLMs handle their own generated questions and assesses their reasoning consistency.",
        "Problem Motivation":"While LLMs are widely used for question answering (QA), their ability to generate valid and well-formed questions remains unclear. Understanding where LLMs struggle with self-generated questions can help improve question-answering benchmarks and enhance reasoning reliability.",
        "Year": "2024",
        "Abstract": "Question answering (QA)—giving correct answers to questions—is a popular task, but we test reverse question answering (RQA): for an input answer, give a question with that answer. Past work tests QA and RQA separately, but we test them jointly, comparing their difficulty, aiding benchmark design, and checking reasoning consistency. We run 16 LLMs on QA and RQA with trivia questions/answers, revealing: 1) Versus QA, LLMs are much less accurate in RQA for numerical answers, but slightly more accurate in RQA for textual answers; 2) LLMs often answer their own invalid questions from RQA accurately in QA, so RQA errors are not from knowledge gaps alone; 3) RQA errors correlate with question difficulty and inversely correlate with answer frequencies in the Dolma corpus; and 4) LLMs struggle to provide valid multi-hop questions. By finding question and answer types that lead to RQA errors, we suggest improvements for LLM reasoning."
    },
    {
        "title": "Exploration of Different Large Language Models for Retrieval-Augmented Generation in Analyzing Wearable Running Data for Sports Physiotherapy",
        "Problem Description":"The study investigates how different parameter-size Large Language Models (LLMs) perform in analyzing biomechanical running data from wearable devices using Retrieval-Augmented Generation (RAG). The goal is to determine the optimal model size that balances accuracy and computational efficiency for sports physiotherapy applications.",
        "Problem Motivation":"Wearable devices generate biomechanical data that can be valuable for physiotherapists to prevent injuries and improve performance. However, processing this data effectively requires advanced AI models. Larger LLMs offer high accuracy but demand significant computational resources, making them impractical for some users. This research aims to identify the most efficient LLM size for real-world physiotherapy applications.",
        "Year": "2024",
        "Abstract": "This study investigated the impact of wearable technologies, particularly advanced biomechanical analytics and machine learning, on sports performance monitoring and intervention strategies within the realm of physiotherapy. The primary aims were to evaluate key performance metrics, individual athlete variations and the efficacy of machine learning-driven adaptive interventions."
    },
    {
        "title": "Evaluating Large Language Models for Automated Cyber Security Alarm Analysis Processes",
        "Problem Description":"The study investigates how Large Language Models (LLMs) can be used to automate the cybersecurity alarm analysis process, particularly in handling alert fatigue caused by an overwhelming number of security notifications. The research assesses different LLMs in their ability to analyze alarms, determine threat levels, and support security operators in decision-making.",
        "Problem Motivation":"Cybersecurity professionals deal with a massive volume of security alerts, leading to 'alert fatigue,' where real threats might be overlooked due to an overload of information. Automating parts of this analysis using LLMs can enhance efficiency, reduce human workload, and improve response times in detecting genuine threats",
        "Year": "2024",
        "Abstract": "A security operations centre (SOC) is a facility where teams of security professionals, supported by advanced technologiesand processes, work together to monitor, detect, and respond to cybersecurity incidents. With advances in AI technology,most of the SOC functions are increasingly becoming AI-driven. Among these, real-time alert monitoring and triage is particularly important. Recent studies, by both industry and academia, have highlighted the problem of alert fatigue and burnout in SOC. Several solutions have been proposed in the literature and by the industry to address this problem. In this paper, we review the existing literature and industry solutions on alert fatigue mitigation through the lenses of automation, augmentation, and human-AI collaboration. Based on the review, we identify four major causes of alert fatigue in SOC. We also examine the shortcomings of existing solutions and propose several potential research directions leveraging AI. By providing a comprehensive analysis of the state-of-the-art approaches and their limitations, this study contributes to the existing literature in an important ield of study. We anticipate that it will inspire new research directions for addressing alert fatigue not just in SOCs but across other Command and Control (C2) domains as well."
    },
    {
        "title": "Automatic Evaluation of Companies' Alignment with EU Taxonomy Using Large Language Models",
        "Problem Description":"The research investigates how Large Language Models (LLMs) can automatically assess companies' alignment with the EU Taxonomy sustainability framework by analyzing corporate sustainability reports. It explores different prompting techniques and retrieval methods to optimize accuracy and relevance in extracting and evaluating information.",
        "Problem Motivation":"Assessing compliance with the EU Taxonomy is currently a manual and time-consuming process for sustainability analysts. Automating this process with LLMs could improve efficiency, reduce human effort, and ensure consistent evaluation of sustainability reports.",
        "Topic": "LLMs in Sustainability Compliance",
        "Year": "2024",
        "Abstract": "This project presents an end-to-end system using Large Language Models (LLM) and Retrieval-Augmented Generation (RAG) to automatically evaluate a company's EU Taxonomy performance based on their sustainability reports by answering two different questions: (1) What is the most suitable prompt between Zero-shot Chain-of-Thought (CoT), Few-shot CoT, and no-CoT prompting, and (2) What is the most suitable retriever system to retrieve EU Taxonomy-related information from company's reports. For the first question, we developed a qualitative human evaluation score to compare the answers' informativeness and correctness. We investigated whether automated metrics such as BERTScore or BLEU correlate with these human-evaluation scores. For the 2nd question, we compare different keyword extraction techniques (for keyword retrievers), query splitting and expansion techniques (for vector retrievers), and investigate the role of reranking in retriever systems. For question (1), results show that Zero-shot CoT prompting performs slightly better than traditional prompting followed by Few-shot CoT prompting, possibly due to the significantly longer prompts of Few-shot CoT. We also discovered that CoT prompting demonstrated a higher correlation between automated and human-evaluation metrics than noCoT prompting. Thus, it is easier to flag errors automatically. For the second question, we discovered: (i) Keyword extraction techniques do not concretely improve BM25 Keyword Retriever's performance; (ii) Splitting long queries into more self-contained sub-queries, whether using separators or using LLMs, achieves considerable performance boost for vector retriever; (iii) LLM-generated hypothetical answer also show significant improvement compared to the naive query splitting method; and (iv) Cross-Encoder reranking often filters out good results annotated by human, and the choice of reranking question also play a significant role in the Cross-Encoder Reranking model's performance. Finally, although our system and evaluation methods are not flawless, we have demonstrated that LLM and RAG can assist humans in extracting information related to EU taxonomy from a company's report and measuring that company's EU Taxonomy performance."
    },
    {
      "title":"Variational Auto-Encoder for Latent Uncertainty Encoding in Large Language Models",
      "Problem Description":"The research explores methods for encoding uncertainty in Large Language Models (LLMs) by introducing a Variational Auto-Encoder (VAE) architecture. The goal is to represent model uncertainty in a probabilistic manner and assess its impact on generated text reliability.",
      "Problem Motivation":"LLMs are widely used in various applications, but they often generate responses with unknown certainty, leading to issues such as hallucinations and misinformation. Providing a structured way to quantify uncertainty in LLM outputs could improve trustworthiness and decision-making.",
      "Year": "2025",
      "Abstract": "This thesis aims to explore methods for encoding uncertainty in machine learning, focusing on Large Language Models (LLMs) in particular. To achieve this, we make use of a Variational Auto-Encoder (VAE) architecture to learn a probabilistic latent representation of the internal embeddings of LLMs. Our findings show that this architecture, in combination with a Kullback Leibler (KL) training objective designed to capture the inherent uncertainty, is a promising method for encoding and estimating uncertainty for LLMs."
    },
    {
      "title":"Using LLMs to aid developers with code comprehension in codebases",
      "Problem Description":"Developers often struggle to understand unfamiliar codebases, particularly when documentation is lacking or previous developers are unavailable. This leads to prolonged onboarding times and difficulty in implementing changes effectively.",
      "Problem Motivation":"Research indicates that developers spend a significant portion of their time comprehending code rather than writing new code. Traditional methods, such as asking experts, are not always available, leading to inefficiencies. Large Language Models (LLMs) have the potential to assist developers by providing explanations and answering queries about code structure and functionality.",
      "Year": "2024",
      "Abstract": "Developers spend significant amounts of time on comprehending code, with research suggesting developers spend up to 70 percent of their time on code comprehension. This is worsened further if there is a lack of proper documentation. With the help of Large Language Models, this could be sped up greatly. However, current research on this topic is limited in scope, mostly focusing on an educational context. In this work, the effectiveness of LLM tools is evaluated in a real-world setting, with the usage of locally running models. Results show that such tools can help developers quickly narrow down where to look in the code when solving tasks. Additionally, results show that developers can get a good low-level understanding of the code without the aid of an expert on the codebase. The nature of this research, with its usage of locally running models, allows for several directions for improvements in future work."
    }
]
